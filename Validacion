# Definir funciones de pérdida, optimizador y callbacks
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import StratifiedKFold

loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)
early_stop = EarlyStopping(monitor='val_loss', patience=60)

# Validación cruzada K-Fold
kfold = StratifiedKFold(n_splits=5, shuffle=True)

# Definir listas para almacenar las métricas
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []

# Realizar validación cruzada y calcular métricas
for train_idx, val_idx in kfold.split(X_train_formated, y_train_formated):
    X_train_fold, X_val_fold = X_train_formated[train_idx], X_train_formated[val_idx]
    y_train_fold, y_val_fold = y_train_formated[train_idx], y_train_formated[val_idx]
    
    # Crear modelo
    
    # Compilar el modelo
    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])
    
    # Entrenar el modelo con callbacks
    history = model.fit(X_train_fold, y_train_fold, epochs=20, batch_size=2,
                        callbacks=[reduce_lr, early_stop], validation_split=0.2,
                        verbose=1)
    
    # Evaluar en el conjunto de prueba
    y_pred_proba = model.predict(X_val_fold)
    y_pred = (y_pred_proba > 0.5).astype(int)  # Convertir probabilidades a clases binarias
    
    # Calcular métricas para el fold actual
    accuracy = accuracy_score(y_val_fold, y_pred)
    precision = precision_score(y_val_fold, y_pred, average='macro')
    recall = recall_score(y_val_fold, y_pred, average='macro')
    f1 = f1_score(y_val_fold, y_pred, average='macro')
    
    # Almacenar las métricas
    accuracy_scores.append(accuracy)
    precision_scores.append(precision)
    recall_scores.append(recall)
    f1_scores.append(f1)

# Calcular la media y desviación estándar de las métricas
mean_accuracy = np.mean(accuracy_scores)
std_accuracy = np.std(accuracy_scores)
mean_precision = np.mean(precision_scores)
std_precision = np.std(precision_scores)
mean_recall = np.mean(recall_scores)
std_recall = np.std(recall_scores)
mean_f1 = np.mean(f1_scores)
std_f1 = np.std(f1_scores)

# Imprimir resultados con variabilidad
print(f'Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}')
print(f'Precision: {mean_precision:.4f} ± {std_precision:.4f}')
print(f'Recall: {mean_recall:.4f} ± {std_recall:.4f}')
print(f'F1-score: {mean_f1:.4f} ± {std_f1:.4f}')
