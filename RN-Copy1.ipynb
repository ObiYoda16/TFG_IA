{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6d240cb-8a29-4b2b-bb12-23743557d478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:21:41.090736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 10:21:41.195312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 10:21:41.196198: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 10:21:41.380925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import layers, models, regularizers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f510b8a-9a6b-441c-97da-b6f7f2e07816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    # Cargar un archivo de audio y convertirlo a un tensor\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    # Resamplear el audio si es necesario\n",
    "    if sample_rate != 16000:\n",
    "        waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "\n",
    "    # Tokenizar la entrada\n",
    "    input_values = tokenizer(waveform.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
    "\n",
    "    # Realizar la inferencia\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Obtener la transcripción predicha\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = tokenizer.decode(predicted_ids[0])\n",
    "\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68673ba-67cb-4c8a-b991-160c8755f811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416daedb-9c8e-4096-9ce1-c3baa01d1421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 07:33:05.845385: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 07:33:05.850581: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-02 07:33:05.850624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self, path_df, path_audio):\n",
    "        self.path_df = \"df_filter.csv\"\n",
    "        self.path_audio = path_audio\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.path_df)\n",
    "        df[\"file_cut_path\"] = self.path_audio + df[\"file_name\"]\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.dataset = df[\"file_cut_path\"]\n",
    "\n",
    "        self.log = []\n",
    "        for i in range(len(df)):\n",
    "            self.log.append(torch.load(\"torch_files14/\" + f\"torch_files14file{i}.pt\"))\n",
    "\n",
    "        self.y = df[\"label\"]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.log, self.y, random_state=42, stratify=self.y\n",
    "        )\n",
    "\n",
    "        self.process_tensors()\n",
    "\n",
    "    def process_tensors(self):\n",
    "        for i in range(len(self.X_train)):\n",
    "            self.X_train[i] = self.X_train[i][0].detach().numpy()\n",
    "            self.X_train[i] = np.concatenate(self.X_train[i])\n",
    "\n",
    "        for i in range(len(self.X_test)):\n",
    "            self.X_test[i] = self.X_test[i][0].detach().numpy()\n",
    "            self.X_test[i] = np.concatenate(self.X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb00adc7-4541-47d0-ae51-9bd82b4052b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_formated\n",
      "y_train_formated\n",
      "X_test_formated\n",
      "y_test_formated\n",
      "Datos cargados\n"
     ]
    }
   ],
   "source": [
    "processor = AudioProcessor(path_df=\"./df_filter.csv\", path_audio=\"../audios/\")\n",
    "X_train   = processor.X_train\n",
    "y_train  = processor.y_train\n",
    "X_test = processor.X_test\n",
    "y_test = processor.y_test\n",
    "\n",
    "X_train_formated = np.array(X_train)\n",
    "y_train_formated = np.array(y_train)\n",
    "X_test_formated = np.array(X_test)\n",
    "y_test_formated = np.array(y_test)\n",
    "\n",
    "print(\"X_train_formated\")\n",
    "X_train_formated.shape\n",
    "print(\"y_train_formated\")\n",
    "y_train_formated.shape\n",
    "print(\"X_test_formated\")\n",
    "X_test_formated.shape\n",
    "print(\"y_test_formated\")\n",
    "y_test_formated.shape\n",
    "\n",
    "\n",
    "print(\"Datos cargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3ff21e-34a6-484c-85e2-429d0f55faef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_formated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc115e92-f32b-419d-9083-579c68143851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir parámetros adicionales\n",
    "params = {\n",
    "    'eval_metric': 'error',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "# Inicialización y entrenamiento del clasificador XGBoost\n",
    "classifier = XGBClassifier(objective=\"binary:logistic\", seed=42, **params)\n",
    "classifier.fit(X_train_formated, y_train_formated, verbose=3, eval_set=[(X_test_formated, y_test_formated)])\n",
    "\n",
    "# Predecir y evaluar el modelo\n",
    "y_pred = classifier.predict(X_test_formated)\n",
    "score = accuracy_score(y_test_trans, y_pred)\n",
    "print(f\"Accuracy: {score}\")\n",
    "\n",
    "# Mostrar otras métricas si están definidas en 'metricas'\n",
    "for metric in metricas:\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298505fb-bfca-435c-b772-abd41816097a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
